1. Core Concept
Neural Networks are algorithms modeled after the human brain's way of processing information. They consist of digital "perceptrons" mimicking biological neurons.

2. Key Components
Input Layer: Where data is fed into the model.

Hidden Layers: Intermediate layers where features are extracted and weights are processed.

Output Layer: Where the result (prediction or classification) is produced.

Weights & Biases: Numerical values determining the strength of connections between neurons.

3. How It Learns (Backpropagation)
The model makes a prediction, compares it with the actual result (Loss Function), and propagates the error backward to update weights.

4. Implementation (Python & NumPy)
Here is a simple example of a single neuron (Perceptron) forward pass:

Coding:

import numpy as np

def sigmoid(x):
    # Activation function: maps input to a value between 0 and 1
    return 1 / (1 + np.exp(-x))

class Neuron:
    def __init__(self, weights, bias):
        self.weights = weights
        self.bias = bias

    def feedforward(self, inputs):
        # Weight inputs, add bias, then use the activation function
        total = np.dot(self.weights, inputs) + self.bias
        return sigmoid(total)

weights = np.array([0, 1]) # w1 = 0, w2 = 1
bias = 4                   # b = 4
n = Neuron(weights, bias)

x = np.array([2, 3])       # x1 = 2, x2 = 3
print(f"Output: {n.feedforward(x)}")
# Output: 0.9990889488055994
